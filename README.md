# NQ Options Trading System - Hierarchical Pipeline Framework

## Quick Start

**Single Entry Point with Flexible Usage**:

```bash
# Run with Databento (Standard E-mini NQ Options - $20 per point)
python3 run_pipeline.py

# Note: Contract arguments are deprecated. Databento automatically fetches
# current Standard E-mini NQ options data. For configuration options:
python3 run_pipeline.py --help
```

This runs the complete Hierarchical Pipeline Analysis Framework with your actual NQ Options EV algorithm using **live market data** when available.

## System Overview

The system uses a **hierarchical pipeline architecture** where each analysis acts as a filter, enricher, and sorter of trading opportunities:

```
Raw Data (1000 strikes) 
    â†“
Risk Analysis: Filter significant exposure â†’ Sort by risk
    â†“ (100 opportunities)
EV Analysis: Filter positive EV â†’ Sort by expected value  
    â†“ (50 opportunities)
Final Results: Top-ranked trading opportunities
```

## Core Components

- **Entry Point**: `run_pipeline.py` - Single command to run everything
- **Pipeline System**: `tasks/options_trading_system/` - Modular analysis framework
- **Configuration**: `tasks/options_trading_system/analysis_engine/pipeline_config.json`
- **Documentation**: `docs/hierarchical_pipeline_framework.md`

## Project Structure

```
/Users/Mike/trading/algos/EOD/
â”œâ”€â”€ CLAUDE.md                           # Project instructions
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ run_pipeline.py                     # ğŸš€ MAIN ENTRY POINT
â”œâ”€â”€ .env                                # Environment variables (API keys)
â”œâ”€â”€ .gitignore                          # Git ignore patterns
â”œâ”€â”€ config/                             # ğŸ“‹ CONFIGURATION PROFILES
â”‚   â”œâ”€â”€ databento_only.json            # Databento-only configuration (default)
â”‚   â”œâ”€â”€ barchart_only.json             # Barchart-only configuration  
â”‚   â”œâ”€â”€ all_sources.json               # All data sources enabled
â”‚   â””â”€â”€ testing.json                   # Testing configuration
â”œâ”€â”€ scripts/                            # ğŸ”§ UTILITY SCRIPTS
â”‚   â”œâ”€â”€ compare_barchart_databento.py  # Data source comparison
â”‚   â”œâ”€â”€ production_monitor.py          # Production monitoring system
â”‚   â”œâ”€â”€ monitoring_dashboard.py        # Web monitoring dashboard
â”‚   â”œâ”€â”€ validate_phase.py              # Phase validation script
â”‚   â”œâ”€â”€ requirements_databento.txt     # Databento dependencies
â”‚   â””â”€â”€ setup_databento.sh             # Databento setup script
â”œâ”€â”€ tests/                              # ğŸ§ª TEST SUITE (32 test files)
â”‚   â”œâ”€â”€ test_config_system.py          # Configuration system tests
â”‚   â”œâ”€â”€ test_pipeline_config.py        # Pipeline configuration tests
â”‚   â”œâ”€â”€ test_pipeline_with_config.py   # Full pipeline tests
â”‚   â”œâ”€â”€ test_databento_integration.py  # Databento integration tests
â”‚   â”œâ”€â”€ test_barchart_api_only.py      # Barchart API tests
â”‚   â”œâ”€â”€ test_databento_api.py          # Databento API tests
â”‚   â”œâ”€â”€ test_databento_nq_options.py   # NQ options specific tests
â”‚   â”œâ”€â”€ test_live_trading_readiness.py # Live trading readiness tests
â”‚   â”œâ”€â”€ test_api_authentication.py     # API authentication tests
â”‚   â”œâ”€â”€ test_edge_cases.py             # Edge case handling tests
â”‚   â””â”€â”€ ... (22 more test files)       # Complete test coverage
â”œâ”€â”€ archive/                            # Legacy files (archived)
â”œâ”€â”€ docs/                               # ğŸ“š DOCUMENTATION
â”‚   â”œâ”€â”€ analysis/                       # Strategy documentation
â”‚   â”œâ”€â”€ data_sources/                   # Data source guides
â”‚   â”œâ”€â”€ live_trading_test_plan.txt     # Comprehensive test plan
â”‚   â””â”€â”€ *.md                           # System documentation
â”œâ”€â”€ outputs/                            # ğŸ“ ORGANIZED OUTPUT STRUCTURE
â”‚   â”œâ”€â”€ YYYYMMDD/                       # Date-based organization
â”‚   â”‚   â”œâ”€â”€ analysis_exports/           # JSON analysis outputs
â”‚   â”‚   â”œâ”€â”€ api_data/                   # API responses
â”‚   â”‚   â”œâ”€â”€ reports/                    # Trading reports
â”‚   â”‚   â””â”€â”€ polygon_api_results/        # Polygon.io results
â”‚   â”œâ”€â”€ config_tests/                   # Configuration test results
â”‚   â”œâ”€â”€ databento_cache/                # Databento cache
â”‚   â””â”€â”€ monitoring/                     # Production monitoring data
â”‚       â”œâ”€â”€ production_metrics.json    # Real-time system metrics
â”‚       â”œâ”€â”€ dashboard.html             # Web monitoring dashboard
â”‚       â””â”€â”€ monitor.log                # Monitoring system logs
â”œâ”€â”€ tasks/options_trading_system/       # ğŸ—ï¸ ACTIVE PIPELINE FRAMEWORK
â”‚   â”œâ”€â”€ config_manager.py               # Configuration management
â”‚   â”œâ”€â”€ analysis_engine/                # Analysis modules
â”‚   â”œâ”€â”€ data_ingestion/                 # Data loading modules
â”‚   â”‚   â”œâ”€â”€ sources_registry.py        # Data source registry
â”‚   â”‚   â”œâ”€â”€ integration.py             # Pipeline integration
â”‚   â”‚   â”œâ”€â”€ barchart_web_scraper/      # Barchart API integration
â”‚   â”‚   â”œâ”€â”€ databento_api/             # Databento CME Globex live data
â”‚   â”‚   â”œâ”€â”€ polygon_api/               # Polygon.io Nasdaq-100 options
â”‚   â”‚   â”œâ”€â”€ interactive_brokers_api/   # Interactive Brokers integration
â”‚   â”‚   â””â”€â”€ tradovate_api_data/        # Tradovate integration
â”‚   â””â”€â”€ output_generation/              # Results output modules
â”œâ”€â”€ templates/                          # ğŸ“‹ DOCUMENTATION TEMPLATES
â”‚   â”œâ”€â”€ phase_template.md               # Template for future phases
â”‚   â””â”€â”€ implementation_notes_template.md # Technical documentation template
â”œâ”€â”€ venv/                               # Python virtual environment
â””â”€â”€ worktrees/                          # Git worktrees for branch work
```

## Configurable Data Sources

The system now supports **easy configuration switching** between data sources:

### Available Configurations
- **`databento_only.json`** - Standard E-mini NQ options (default, $20 per point)
- **`barchart_only.json`** - Micro E-mini NQ options ($2 per point)  
- **`all_sources.json`** - All data sources enabled
- **`testing.json`** - Test configuration with saved data

### Switching Data Sources
```bash
# Use different configuration profile
# Edit config/databento_only.json to enable/disable sources
# Or load different profile in run_pipeline.py

# Example: Switch from Databento to Barchart
# In config/databento_only.json, change:
# "databento": {"enabled": false}
# "barchart": {"enabled": true}
```

### Analysis Strategies
The system supports multiple analysis strategies via configuration:

- **Conservative**: Risk-first filtering with strict thresholds
- **Aggressive**: EV-first filtering with broader criteria  
- **Technical**: Pattern-first filtering for technical traders
- **Scalping**: Fast execution for intraday trading

Edit configuration files in `config/` directory to switch strategies and data sources.

## File Organization

### Clean Root Directory
The root directory contains only essential files:
- **`run_pipeline.py`** - Main entry point for the trading system
- **`README.md`** - This documentation file
- **`.env`** - Configuration file (API keys)
- **`.gitignore`** - Git configuration

All test files have been organized into the `tests/` directory for better structure.

### Directory Structure
```
â”œâ”€â”€ tasks/                     # Core implementation modules
â”‚   â””â”€â”€ options_trading_system/
â”‚       â”œâ”€â”€ analysis_engine/   # Analysis algorithms and strategies
â”‚       â”œâ”€â”€ data_ingestion/    # Data source integrations
â”‚       â””â”€â”€ output_generation/ # Report generators
â”œâ”€â”€ config/                    # Configuration profiles
â”œâ”€â”€ docs/                      # Documentation and guides
â”œâ”€â”€ outputs/                   # Generated outputs (auto-organized)
â”œâ”€â”€ scripts/                   # Utility scripts
â”œâ”€â”€ tests/                     # Test files
â””â”€â”€ archive/                   # Legacy code for reference
```

### Automated Output Management
All generated files are automatically organized by date and type:

- **Analysis Results**: `outputs/YYYYMMDD/analysis_exports/` - JSON exports with trade recommendations  
- **Trading Reports**: `outputs/YYYYMMDD/reports/` - Human-readable trading reports
- **System Logs**: `outputs/YYYYMMDD/logs/` - Pipeline execution logs
- **API Data**: `outputs/YYYYMMDD/api_data/` - Live market data snapshots
- **Performance Data**: `outputs/performance_tracking/` - System metrics

**No manual file management required** - the system automatically creates organized directories and routes all outputs appropriately.

## Data Sources

The system supports multiple data sources for comprehensive market coverage:

### Live Data Sources
- **Databento** - CME Globex live futures and options data ($179/month subscription)
- **Barchart** - Web API for options chains and pricing
- **Polygon.io** - Nasdaq-100 options and market data
- **Interactive Brokers** - Real-time trading data
- **Tradovate** - Futures trading platform integration

### Setup Instructions
```bash
# Install Databento dependencies
pip install -r scripts/requirements_databento.txt

# Configure API keys (see docs/data_sources/databento.md)
export DATABENTO_API_KEY=your-key-here

# Test integration
python tests/test_databento_integration.py

# Test configuration system
python tests/test_config_system.py
```

See [Data Sources Documentation](docs/data_sources/) for detailed setup guides.

## Production Monitoring

The system includes comprehensive production monitoring capabilities:

### Monitoring Features
- **Real-time Metrics**: System health, trading performance, cost tracking
- **Web Dashboard**: Visual monitoring interface with auto-refresh
- **Alert System**: Configurable thresholds with multiple alert levels
- **Historical Tracking**: 30-day retention of all metrics

### Quick Start Monitoring
```bash
# Start production monitoring
python3 scripts/production_monitor.py

# Launch web dashboard
python3 scripts/monitoring_dashboard.py

# View dashboard at: http://localhost:8080/dashboard.html
```

### Monitored Metrics
- **Trading Performance**: Signal accuracy, latency, win/loss ratios
- **System Health**: CPU, memory, disk usage, uptime
- **Cost Management**: Daily costs, budget tracking, API usage
- **Business Metrics**: ROI tracking, profit/loss analysis

See [Production Monitoring Guide](docs/PRODUCTION_MONITORING.md) for detailed setup and configuration.

## Algorithm

Uses your actual NQ Options Expected Value algorithm with:
- **Risk Analysis** (35% OI, 25% Volume, 25% PCR, 15% Distance weighting)
- **Institutional Positioning** ("Who has more skin in the game?")
- **Quality Filtering** (Min EV: 15 points, Min Probability: 60%)

## Development

- **Add Analysis**: Implement `PipelineAnalysis` interface in new module
- **Reorder Pipeline**: Change order in configuration file
- **ML Optimization**: Tune weights and thresholds via config

## Historical Context

This system replaces the previous task-based implementation. All legacy files are preserved in the `archive/` directory for reference.

**Ready to trade with: `python3 run_pipeline.py`** ğŸš€